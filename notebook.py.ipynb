{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing our data\n",
    "1. First, we grab all our images with proper classes (every directory is a class)\n",
    "2. Then we write the info into a DataFrame with columns (filepath, classname, classid)\n",
    "3. Split our data frame to train frame and test frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>classname</th>\n",
       "      <th>classid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_images/Lotus/16905dde87.jpg</td>\n",
       "      <td>Lotus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flower_images/Lotus/839f7d1a14.jpg</td>\n",
       "      <td>Lotus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flower_images/Lotus/6acf5327ad.jpg</td>\n",
       "      <td>Lotus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flower_images/Lotus/327793cdf0.jpg</td>\n",
       "      <td>Lotus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flower_images/Lotus/c8e4698aa0.jpg</td>\n",
       "      <td>Lotus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filepath classname classid\n",
       "0  flower_images/Lotus/16905dde87.jpg     Lotus       0\n",
       "1  flower_images/Lotus/839f7d1a14.jpg     Lotus       0\n",
       "2  flower_images/Lotus/6acf5327ad.jpg     Lotus       0\n",
       "3  flower_images/Lotus/327793cdf0.jpg     Lotus       0\n",
       "4  flower_images/Lotus/c8e4698aa0.jpg     Lotus       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_dataframe(directory: str) -> pd.DataFrame:\n",
    "  '''\n",
    "  Creates a data frame from a directory.\n",
    "  Every subfolder represents a class.\n",
    "  Every subfolder contains images of that class.\n",
    "  '''\n",
    "\n",
    "  # Get all subfolders\n",
    "  subfolders = [f.path for f in os.scandir(directory) if f.is_dir()]\n",
    "\n",
    "  # create an empty data frame\n",
    "  frame = pd.DataFrame(columns=['filepath', 'classname', 'classid'])\n",
    "\n",
    "  # iterate over all subfolders\n",
    "  for i, subfolder in enumerate(subfolders):\n",
    "    # get all images in the subfolder\n",
    "    images = [f.path for f in os.scandir(subfolder) if f.is_file()]\n",
    "\n",
    "    # create a data frame for the subfolder\n",
    "    df = pd.DataFrame(columns=['filepath', 'classname', 'classid'])\n",
    "    df['filepath'] = images\n",
    "    df['classname'] = os.path.basename(subfolder)\n",
    "    df['classid'] = i\n",
    "\n",
    "    # append the subfolder data frame to the main data frame\n",
    "    frame = pd.concat([frame, df], ignore_index=True)\n",
    "\n",
    "  return frame\n",
    "\n",
    "flowers_frame = create_dataframe('flower_images')\n",
    "flowers_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Generic, Callable\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "T = TypeVar('T')\n",
    "ImageTransformer = Callable[[Image.Image], T]\n",
    "\n",
    "class FlowersDataset(Dataset, Generic[T]):\n",
    "  def __init__(self, frame: pd.DataFrame, transform: ImageTransformer | None = None) -> None:\n",
    "    self.frame = frame\n",
    "    self.transform = transform\n",
    "  \n",
    "  def __len__(self) -> int:\n",
    "    return len(self.frame)\n",
    "  \n",
    "  def __getitem__(self, index: int) -> tuple[Image.Image | T, int]:\n",
    "    row = self.frame.iloc[index]\n",
    "    filepath, classid = row['filepath'], row['classid']\n",
    "    image = Image.open(filepath)\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    return image, classid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def image_to_tensor(image: Image) -> torch.Tensor:\n",
    "  '''\n",
    "  Converts an image to a tensor.\n",
    "  '''\n",
    "  image = image.convert('RGB')\n",
    "  image = image.resize((224, 224))\n",
    "  array = np.array(image)\n",
    "  array = array.transpose((2, 0, 1))\n",
    "  return torch.from_numpy(array).to(torch.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(len(flowers_frame) * 0.8)\n",
    "test_size = len(flowers_frame) - train_size\n",
    "\n",
    "train_frame, test_frame = random_split(flowers_frame, [train_size, test_size])\n",
    "train_frame, test_frame = train_frame.dataset, test_frame.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FlowersDataset(train_frame, transform=image_to_tensor)\n",
    "test_dataset = FlowersDataset(test_frame, transform=image_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, _ = train_dataset[0]\n",
    "image.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Neural Network\n",
    "Here I use PyTorch for our neural network. We are trying to build a CNN <br>\n",
    "First of all, we define our building blocks, which are convolutional units and dense units <br>\n",
    "Then, we are building our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ConvUnit(nn.Module):\n",
    "  '''\n",
    "  Convolutional Unit consisting of\n",
    "  - Convolutional Layer\n",
    "  - ReLU Activation\n",
    "  - Batch Normalization\n",
    "  - Max Pooling\n",
    "  '''\n",
    "  def __init__(self, in_channels: int, out_channels: int, conv_kernel: int = 3, pool_kernel: int = 2) -> None:\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=conv_kernel, padding=1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=pool_kernel, stride=pool_kernel)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.conv(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.batch_norm(x)\n",
    "    x = self.pool(x)\n",
    "    return x\n",
    "  \n",
    "\n",
    "class DenseUnit(nn.Module):\n",
    "  '''\n",
    "  Dense Unit consisting of\n",
    "  - Linear Layer\n",
    "  - ReLU Activation\n",
    "  - Batch Normalization\n",
    "  - Dropout\n",
    "  '''\n",
    "  def __init__(self, in_features: int, out_features: int, droupout: float = 0.0, normalization: bool = True) -> None:\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(in_features, out_features)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.normalization = normalization\n",
    "    if normalization:\n",
    "      self.batch_norm = nn.BatchNorm1d(out_features)\n",
    "    self.dropout = nn.Dropout(droupout)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.linear(x)\n",
    "    x = self.relu(x)\n",
    "    if self.normalization:\n",
    "      x = self.batch_norm(x)\n",
    "    x = self.dropout(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FlowerCNN(nn.Module):\n",
    "  '''\n",
    "  Convolutional Neural Network for classifying 5 types of flowers:\n",
    "  - Lilly\n",
    "  - Lotus\n",
    "  - Orchid\n",
    "  - Sunflower\n",
    "  - Tulip\n",
    "\n",
    "  Takes RGB images 224x224 pixels as input turned into tensors\n",
    "  '''\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.extractor = nn.Sequential(\n",
    "      ConvUnit(3, 32),\n",
    "      ConvUnit(32, 64),\n",
    "      ConvUnit(64, 128),\n",
    "      ConvUnit(128, 256),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(\n",
    "      DenseUnit(12544, 1024, droupout=0.2),\n",
    "      DenseUnit(1024, 256, droupout=0.2),\n",
    "      DenseUnit(256, 64, droupout=0.2),\n",
    "      DenseUnit(64, 5),\n",
    "    )\n",
    "    self.output_function = nn.Softmax(dim=1)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.extractor(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.classifier(x)\n",
    "    x = self.output_function(x)\n",
    "    return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Trainer:\n",
    "  '''\n",
    "  Trainer for a PyTorch model.\n",
    "  Performs training and validation of a model.\n",
    "  Trainer contains train and validation history.\n",
    "  '''\n",
    "  def __init__(self, model: nn.Module, learning_rate: float = 0.001) -> None:\n",
    "    self.device = torch.device(self.device_name)\n",
    "    self.model = model.to(self.device)\n",
    "    self.loss_function = nn.CrossEntropyLoss()\n",
    "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "    self.train_history = []\n",
    "    self.validation_history = []\n",
    "\n",
    "  @property\n",
    "  def device_name(self) -> str:\n",
    "    if torch.cuda.is_available():\n",
    "      return 'cuda'\n",
    "    if torch.backends.mps.is_available():\n",
    "      return 'mps'\n",
    "    return 'cpu'\n",
    "  \n",
    "  def train(self, train_loader: DataLoader, epochs: int = 10) -> None:\n",
    "    self.model.train()\n",
    "    for epoch in range(epochs):\n",
    "      epoch_loss, epoch_accuracy = 0.0, 0.0\n",
    "      for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        epoch_accuracy += torch.sum(predictions == labels.data)\n",
    "      epoch_loss /= len(train_loader.dataset)\n",
    "      epoch_accuracy /= len(train_loader.dataset)\n",
    "      self.train_history.append((epoch_loss, epoch_accuracy.item()))\n",
    "      print(f'Epoch {epoch+1}: loss={epoch_loss}, accuracy={epoch_accuracy}')\n",
    "  \n",
    "  def validate(self, validation_loader: DataLoader) -> tuple[float, float]:\n",
    "    self.model.eval()\n",
    "    epoch_loss, epoch_accuracy = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in validation_loader:\n",
    "        inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        epoch_accuracy += torch.sum(predictions == labels.data)\n",
    "    epoch_loss /= len(validation_loader.dataset)\n",
    "    epoch_accuracy /= len(validation_loader.dataset)\n",
    "    self.validation_history.append((epoch_loss, epoch_accuracy.item()))\n",
    "    print(f'Validation: loss={epoch_loss}, accuracy={epoch_accuracy}')\n",
    "    return epoch_loss, epoch_accuracy\n",
    "  \n",
    "  def save_model(self, parent_dir: str) -> None:\n",
    "    if not self.validation_history:\n",
    "      name = 'model.pth'\n",
    "    else:\n",
    "      _, accuracy = self.validation_history[-1]\n",
    "      name = f'model_{accuracy:.4f}.pth'\n",
    "    path = os.path.join(parent_dir, 'model.pth')\n",
    "    state = self.model.state_dict()\n",
    "    torch.save(state, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history: list[tuple[float, float]], label: str) -> None:\n",
    "  loss = [item[0] for item in history]\n",
    "  accuracy = [item[1] for item in history]\n",
    "  plt.plot(loss, label=f'{label} Loss')\n",
    "  plt.plot(accuracy, label=f'{label} Accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlowerCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=1.4182804023742677, accuracy=0.5232000350952148\n",
      "Epoch 2: loss=1.3341190546035766, accuracy=0.6386000514030457\n",
      "Epoch 3: loss=1.273484115409851, accuracy=0.7062000632286072\n",
      "Epoch 4: loss=1.2116063285827636, accuracy=0.7714000344276428\n",
      "Epoch 5: loss=1.1578969974517823, accuracy=0.8270000219345093\n",
      "Epoch 6: loss=1.1172088399887086, accuracy=0.8628000617027283\n",
      "Epoch 7: loss=1.088782986831665, accuracy=0.8872000575065613\n",
      "Epoch 8: loss=1.2475191577911378, accuracy=0.6856000423431396\n",
      "Epoch 9: loss=1.1222258472442628, accuracy=0.8336000442504883\n",
      "Epoch 10: loss=1.0886648063659667, accuracy=0.8650000691413879\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss=1.0318425260543824, accuracy=0.9162000417709351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tikhon/Documents/flowers/.venv/lib/python3.11/site-packages/torch/_tensor_str.py:115: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:218.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0318425260543824, tensor(0.9162, device='mps:0'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
